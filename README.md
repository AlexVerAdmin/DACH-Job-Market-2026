# AI & Data Market Research (DACH Region 2026)

Комплексная система мониторинга и анализа рынка труда в сфере Data Science, AI и Аналитики для региона DACH (Германия, Австрия, Швейцария).

##  Основные возможности
*   **Мульти-источниковый сбор**: Интеграция с Adzuna (агрегатор), StepStone (прямой скрапинг), Xing и официальным API биржи труда Германии (Arbeitsagentur).
*   **Умная дедупликация**: Использование MD5-сигнатур (Title + Company + Location) для объединения данных об одной и той же вакансии из разных источников.
*   **Приоритетность данных**: Автоматическое замещение оценочных зарплат (Predicted) реальными данными от прямых работодателей.
*   **NLP Анализ навыков**: Автоматическое извлечение ключевых технологий (Python, SQL, AI, Cloud) из полных текстов вакансий.
*   **Многопоточность**: Быстрое обогащение данных полными описаниями через `ThreadPoolExecutor`.

##  Структура проекта
*   **`src/`**  Исходный код системы
    *   **`scrapers/`**  Модули для работы с площадками (Adzuna, StepStone, Xing, Arbeitsagentur).
    *   **`database_manager.py`**  Управление базой SQLite, логика UPSERT и дедупликации.
    *   **`description_manager.py`**  Скрапер полных текстов описаний вакансий.
    *   **`skill_extractor.py`**  Анализ текстов и извлечение навыков через регулярные выражения.
    *   **`data_utils.py`**  Нормализация названий городов и очистка текстов от гендерных суффиксов.
*   **`main.py`**  Главный оркестратор (Pipeline) в корне проекта.
*   **`data/`**  База данных `jobs_database.sqlite` (в .gitignore).
*   **`notebooks/`**  Интерактивный анализ в `market_research.ipynb`.

##  Инструкция по запуску

### 1. Подготовка
Создайте файл `.env` в корне проекта и добавьте ключи:
```env
ADZUNA_APP_ID=your_id
ADZUNA_APP_KEY=your_key
DEEPL_API_KEY=your_deepl_key
```

### 2. Запуск команд
Главный скрипт `main.py` поддерживает различные режимы работы через флаги:

| Команда | Описание |
| :--- | :--- |
| `python main.py` | **Полный цикл**: Поиск новых вакансий, обогащение описаний и извлечение навыков. |
| `python main.py --scrape` | **Только поиск**: Сбор новых вакансий без скачивания полных описаний. |
| `python main.py --source adzuna` | **По конкретному источнику**: Запуск скрапинга только для одной площадки (`adzuna`, `stepstone`, `xing`, `aa`). |
| `python main.py --enrich` | **Обогащение**: Докачка полных текстов описаний для существующих вакансий. |
| `python main.py --translate` | **Перевод**: Перевод заголовков вакансий на русский язык через DeepL API. |
| `python main.py --skills` | **Навыки**: Запуск анализа текстов и извлечение навыков. |
| `python main.py --reset` | **Сброс**: Полная очистка базы данных (требует подтверждения). |
| `python main.py --test` | **Тест**: Запуск для 1 роли и 1 страницы. |

##  Рекомендуемый порядок наполнения базы (Workflow)
Если вы планируете заниматься анализом отдельно, выполняйте команды в этой последовательности:

1. **`python main.py --reset`** (По желанию) — Очистить всё и начать с нуля.
2. **`python main.py --scrape`** — Сбор первичных данных (заголовки, компании, ссылки).
3. **`python main.py --enrich`** — Загрузка полных описаний вакансий (требуется для извлечения навыков).
4. **`python main.py --skills`** — Извлечение навыков (Python, SQL, Tableau и т.д.) из текстов.
5. **`python main.py --translate`** — (Опционально) Перевод заголовков для наглядности отчетов.

После выполнения этих шагов файл `data/jobs_database.sqlite` готов к анализу в Jupyter Notebook или BI-системах.